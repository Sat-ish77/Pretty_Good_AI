# Architecture

The system is a **FastAPI webhook server** that drives outbound phone calls through **Twilio**. When `call_manager.py` initiates a call, Twilio dials the Pretty Good AI test number and connects to our server via ngrok. The server uses Twilio's `<Gather input="speech">` verb to capture what the AI agent says in real-time — Twilio handles the speech recognition on its end and posts the transcribed text to our `/handle-response` endpoint. That text, along with the full conversation history, is sent to **GPT-4o** with a scenario-specific system prompt that defines the patient's persona and goals. GPT-4o returns what the patient should say next, and we send it back as `<Say>` TwiML using a Polly Neural voice. Twilio speaks the response and immediately starts listening again, creating a continuous conversation loop until the patient says goodbye or the turn limit is reached. Every call's transcript is saved to disk, and `bug_analyzer.py` feeds them to GPT-4o post-call to automatically identify bugs.

**Key design choices:** I initially built the pipeline with `<Record>` + OpenAI Whisper for transcription and ElevenLabs for text-to-speech, but the combined latency of downloading audio, transcribing, generating a response, synthesizing speech, and serving the audio file back created 8–12 seconds of dead air per turn — causing the agent to talk over our bot. I switched to `<Gather>` + `<Say>`, which offloads speech recognition and TTS entirely to Twilio, cutting per-turn latency to ~2–3 seconds (only the GPT-4o call remains). Conversation state is held in-memory per `CallSid` since calls are short-lived and sequential — no database needed. The scenario system is data-driven: each test case is a dict in `scenarios.py` with a persona prompt and opening line, making it trivial to add new ones. GPT-4o signals end-of-call via an `[END]` token rather than fragile goodbye-phrase detection.
